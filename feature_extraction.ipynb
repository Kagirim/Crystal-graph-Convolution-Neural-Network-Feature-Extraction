{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LGSU0fojEen"
   },
   "source": [
    "# Import libraries \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZILpNhJwcj7k"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFzmuwbMjKu9"
   },
   "source": [
    "# Read the Csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZ6YUIj_HrCd"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/content/unit_cell_catalog2000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-uIrXe-aqRI"
   },
   "source": [
    "Classify into first_nodes for first group and sec_node for the second\n",
    "split the x, y and z nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fws9rT9OQOHo",
    "outputId": "0c2c23fa-ac27-4f24-eeba-f65a2c8f213a"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from numpy.core.fromnumeric import shape\n",
    "\n",
    "# Create a list of all column names\n",
    "column_names = df.columns.values.tolist()\n",
    "\n",
    "# Create empty dataframes to store data\n",
    "nodal_positions = pd.DataFrame()\n",
    "bar_connectivity = pd.DataFrame()\n",
    "first_nodes = pd.DataFrame()\n",
    "second_nodes = pd.DataFrame()\n",
    "x_nodes = pd.DataFrame()\n",
    "y_nodes = pd.DataFrame()\n",
    "z_nodes = pd.DataFrame()\n",
    "\n",
    "# Iterate the whole dataframe looking for specific rows and sorting them into respective dataframes\n",
    "for index, column_name in enumerate(column_names):\n",
    "    # Find the nodal positions first using regex\n",
    "    if re.search(\"^nodal_positions\", column_name):\n",
    "        nodal_positions[column_name] = df.iloc[: , index]\n",
    "        node_num = int(re.search(\"^nodal_positions_(\\d+?)_\", column_name).group(1))\n",
    "\n",
    "        # columns ending with \"1\" represent the x node\n",
    "        if column_name.endswith(\"1\"):\n",
    "            x_nodes[node_num] = df.iloc[: , index]\n",
    "\n",
    "        # columns ending with \"2\" represent the y node\n",
    "        if column_name.endswith(\"2\"):\n",
    "            y_nodes[node_num] = df.iloc[: , index]\n",
    "\n",
    "        # columns ending with \"3\" represent the z node\n",
    "        if column_name.endswith(\"3\"):\n",
    "            z_nodes[node_num] = df.iloc[: , index]\n",
    "\n",
    "    # Secondly, find the bar connections  using regex\n",
    "    if re.search(\"^bar_connectivity\", column_name):\n",
    "        \n",
    "        edge_num = int(re.search(\"^bar_connectivity_(\\d+?)_\", column_name).group(1))\n",
    "        bar_connectivity[column_name] = df.iloc[: , index]\n",
    "\n",
    "        # Find the node pairs and store them in respective DF\n",
    "        if column_name.endswith(\"1\"):\n",
    "            first_nodes[edge_num] = df.iloc[: , index]\n",
    "        if column_name.endswith(\"2\"):\n",
    "            second_nodes[edge_num] = df.iloc[: , index]\n",
    "\n",
    "# replace the NAN values with 0\n",
    "x_nodes = x_nodes.fillna(0)\n",
    "y_nodes = y_nodes.fillna(0)\n",
    "z_nodes = z_nodes.fillna(0)\n",
    "first_nodes = first_nodes.fillna(0)\n",
    "second_nodes = second_nodes.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylzEsFH7jyS_"
   },
   "source": [
    "Calculate the distace between atoms (nodes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1x_PAZK7Uo6K",
    "outputId": "7eecea31-d1c9-4510-9372-cf0ea29a0423"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# create necessary empty dataframes\n",
    "distances = pd.DataFrame()\n",
    "\n",
    "xyz = pd.DataFrame()\n",
    "imn = pd.DataFrame()\n",
    "\n",
    "# Iterate the series of pairs of nodes concurently\n",
    "for (index1, s1), (index2, s2) in zip(first_nodes.iterrows(), second_nodes.iterrows()):\n",
    "\n",
    "    # iterate the column names hich represent the edge\n",
    "    for edge_number in list(first_nodes.columns):\n",
    "        # Find the two nodes connected to the particular edge\n",
    "        node1 = int(s1[edge_number])\n",
    "        node2 = int(s2[edge_number])\n",
    "\n",
    "        try:\n",
    "            x1 = x_nodes[node1][index1]\n",
    "            x2 = x_nodes[node2][index2]\n",
    "\n",
    "            y1 = y_nodes[node1][index1]\n",
    "            y2 = y_nodes[node2][index2]\n",
    "\n",
    "            z1 = z_nodes[node1][index1]\n",
    "            z2 = z_nodes[node2][index2]\n",
    "\n",
    "            xyz[\"xyz_{}\".format(edge_number)]\n",
    "            \n",
    "            edge_length = math.sqrt((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2)\n",
    "\n",
    "            i = (x2 - x1) / edge_length\n",
    "            m = (y2 - y1) / edge_length\n",
    "            n = (z2 - z1) / edge_length\n",
    "        except:\n",
    "            edge_length = 0\n",
    "\n",
    "            i, m, n = 0, 0, 0\n",
    "\n",
    "        distances[\"dist_\".format(edge_number)] = edge_length\n",
    "\n",
    "        imn[\"imn_{}\".format(edge_number)] = [i, m, n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgFORxEzU0eY"
   },
   "source": [
    "Compute node connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "jp9IFV6EU5Ib",
    "outputId": "d7c7204e-2d9f-4a94-c5e2-dde1c6078dde"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "node_connections = pd.DataFrame()\n",
    "column_names = bar_connectivity.columns.values.tolist()\n",
    "\n",
    "for name in column_names:\n",
    "    edge_num = int(re.search(\"^bar_connectivity_(\\d+?)_\", name).group(1))\n",
    "    node_connections[\"node_connectivity_{}\".format(edge_num)] = bar_connectivity[bar_connectivity == edge_num].count(axis=1)\n",
    "\n",
    "node_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MQNAlvZMVRG"
   },
   "source": [
    "Extract a, b, c, alpha, beta, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FscL_js0MiJB"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "constant_features = df[[\"a\", \"b\", \"c\", \"alpha\", \"beta\", \"gamma\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7pvX-31mWcD"
   },
   "source": [
    "Build a dataframe to contain all computed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_RIkwFJinnp"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "model_data = pd.concat([node_connections, imn, constant_features], axis=1)\n",
    "y_vector = df[[\"Cx\", \"Cy\", \"Cz\", \"nx\", \"ny\", \"nz\"]]\n",
    "model_data = model_data.to_json(\"multiclassfication.json\", orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuhJ1cjWrGG4"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJZvvrNyXohM"
   },
   "source": [
    "Install All necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XI7N52VXrqy"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# !pip install pymatgen\n",
    "# !pip install mendeleev \n",
    "# !pip install graphviz \n",
    "# !pip install pydot \n",
    "# !pip install sklearn\n",
    "# !pip install crysnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcbIcXafXMPO"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from crysnet.data import Dataset\n",
    "from crysnet.data.generator import GraphGenerator\n",
    "from crysnet.models import GNN\n",
    "from crysnet.models.gnnmodel import CgcnnModel\n",
    "from pymatgen.core.structure import Structure\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hAt6rq1wIzP"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "ModulePath = Path('/content/dataset_multiclassification.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "RJxb4LUmvx89",
    "outputId": "92d0c466-64b2-4fa0-cd54-453ac6d27630"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(task_type='multiclassification', data_path=ModulePath)\n",
    "BATCH_SIZE = 1600\n",
    "DATA_SIZE = 2000\n",
    "CUTOFF = 2.5\n",
    "\n",
    "#structure the dataset for consumption by model\n",
    "# dataset.prepare_x(model_data)\n",
    "dataset.prepare_y(y_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "gSjp-9mlxy8p",
    "outputId": "b06a8f64-9598-4cb5-f0c0-044f659bf6d1"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "Generators = GraphGenerator(dataset, data_size=DATA_SIZE, batch_size=BATCH_SIZE, cutoff=CUTOFF)\n",
    "train_data = Generators.train_generator\n",
    "valid_data = Generators.valid_generator\n",
    "test_data = Generators.test_generator\n",
    "multiclassification = Generators.multiclassification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yy7kYDh5Zyxq"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "gnn = GNN(model=CgcnnModel, atom_dim=16, bond_dim=64, num_atom=118, \n",
    "          state_dim=16, sp_dim=230, units=32, edge_steps=1, \n",
    "          message_steps=1, transform_steps=1, num_attention_heads=8, \n",
    "          dense_units=64, output_dim=64, readout_units=64, dropout=0.0, \n",
    "          reg0=0.00, reg1=0.00, reg2=0.00, reg3=0.00, reg_rec=0.00, batch_size=BATCH_SIZE, \n",
    "          spherical_harmonics=True, regression=dataset.regression, optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krkGf758rDwR"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  gnn.train(train_data, valid_data, test_data, epochs=700, lr=3e-3, warm_up=True, load_weights=False, verbose=1, checkpoints=None, save_weights_only=True, workdir=ModulePath)\n",
    "  gnn.predict_datas(test_data, workdir=ModulePath)    # predict on test datas with labels\n",
    "except Exception as err:\n",
    "  print(err)\n",
    "y_pred_keras = gnn.predict(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1efKpCv6wXJ"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13 ('cgcnn')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n cgcnn ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matdgl.data import Dataset\n",
    "from matdgl.models import Finetune\n",
    "from matdgl.data.generator import GraphGenerator\n",
    "from matdgl.models.finetune import FinetuneTransformer, FinetuneTransformerRes\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(88)\n",
    "tf.random.set_seed(88)\n",
    "\n",
    "# get current work dir of test.py\n",
    "ModulePath = Path(__file__).parent.absolute()\n",
    "\n",
    "# read datas from ModulePath/datas/multiclassfication.json\n",
    "print('reading dataset...')\n",
    "'multiclassification'\n",
    "'topology_multi'\n",
    "'formation_energy'\n",
    "'regression'\n",
    "'my_regression'\n",
    "start = time.time()\n",
    "dataset = Dataset(task_type='topology_multi', data_path=ModulePath, ratio=[0.6, 0.8])\n",
    "end = time.time()\n",
    "run_time = end - start\n",
    "print('done')\n",
    "print('run time:  {:.2f} s'.format(run_time))\n",
    "print(dataset.dataset_file)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DATA_SIZE = None\n",
    "CUTOFF = 4.5\n",
    "\n",
    "# building batch generator for model trainning\n",
    "Generators = GraphGenerator(dataset, data_size=DATA_SIZE, batch_size=BATCH_SIZE, cutoff=CUTOFF)\n",
    "train_data = Generators.train_generator\n",
    "valid_data = Generators.valid_generator\n",
    "test_data = Generators.test_generator\n",
    "\n",
    "#if task is multiclassfication, should define variable multiclassifiction\n",
    "multiclassification = Generators.multiclassification \n",
    "\n",
    "epochs=32\n",
    "lr=1e-3\n",
    "\n",
    "# default trainning parameters\n",
    "state_dim=16\n",
    "sp_dim=230\n",
    "output_dim=32\n",
    "readout_units=128\n",
    "dropout=0.0\n",
    "reg2=0.0\n",
    "reg3=0.0\n",
    "reg_rec=0.0\n",
    "regression=dataset.regression\n",
    "optimizer = 'Adam'\n",
    "\n",
    "print('\\n----- parameters -----',\n",
    "    '\\ntask_type: ', dataset.task_type,\n",
    "    '\\nsample_size: ', Generators.data_size,\n",
    "    '\\ncutoff: ', CUTOFF,\n",
    "    '\\nstate_dim: ', state_dim,\n",
    "    '\\nsp_dim: ', sp_dim,\n",
    "    '\\noutput_dim: ', output_dim,\n",
    "    '\\nreadout_units: ', readout_units,\n",
    "    '\\ndropout: ', dropout,\n",
    "    '\\nreg2: ', reg2,\n",
    "    '\\nreg3: ', reg3,\n",
    "    '\\nreg_rec: ', reg_rec,\n",
    "    '\\noptimizer: ', optimizer,\n",
    "    '\\nmulticlassification: ', multiclassification,\n",
    "    '\\nregression: ', regression,)\n",
    "\n",
    "del dataset\n",
    "\n",
    "# default model is a GraphTransformer model, can be changed to MPNN model by set 'model=MpnnModel'\n",
    "gnn = Finetune(model=FinetuneTransformerRes,\n",
    "        state_dim=state_dim,\n",
    "        sp_dim=sp_dim,\n",
    "        output_dim=output_dim,\n",
    "        readout_units=readout_units,\n",
    "        dropout=dropout,\n",
    "        reg2=reg2,\n",
    "        reg3=reg3,\n",
    "        reg_rec=reg_rec,\n",
    "        optimizer = optimizer,\n",
    "        regression=regression,\n",
    "        multiclassification=multiclassification,\n",
    "        )\n",
    "\n",
    "# trainning model\n",
    "gnn.train(train_data, valid_data, test_data, epochs=epochs, lr=lr, warm_up=True,\\\n",
    "             verbose=1, checkpoints=None, save_weights_only=True, workdir=ModulePath)\n",
    "\n",
    "print('\\n----- parameters -----',\n",
    "    '\\nsample_size: ', Generators.data_size,\n",
    "    '\\ncutoff: ', CUTOFF,\n",
    "    '\\nstate_dim: ', state_dim,\n",
    "    '\\nsp_dim: ', sp_dim,\n",
    "    '\\noutput_dim: ', output_dim,\n",
    "    '\\nreadout_units: ', readout_units,\n",
    "    '\\noptimizer: ', optimizer,\n",
    "    '\\nmulticlassification: ', multiclassification,\n",
    "    '\\nregression: ', regression,\n",
    "    '\\nepochs: ', epochs,\n",
    "    '\\nlr: ', lr)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cgcnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "72d3997e1c0289df2798320619b193253c1d7bc6403fa0c8c6814200e41740cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
